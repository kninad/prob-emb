{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "small_title_set = {\"The Hunger Games (The Hunger Games, #1)\", \"Harry Potter and the Sorcerer's Stone (Harry Potter, #1)\",\"Twilight (Twilight, #1)\", \"To Kill a Mockingbird\", \"The Great Gatsby\", \"The Fault in Our Stars\", \"The Hobbit\", \"The Catcher in the Rye\", \"Angels & Demons  (Robert Langdon, #1)\", \"Pride and Prejudice\"}\n",
    "print(len(small_title_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "rating_threshold = 3.5 #only counted the usr rating if it is rated above the rating threshold\n",
    "user_count_threshold = 10 #only keep the bk_id if the bk is rated by user for more than user_count_threshold times\n",
    "split = [0.8, 0.1, 0.1] #train, dev, test split\n",
    "#INPUT_DIR = '../../../data/the-movies-dataset/'\n",
    "INPUT_DIR ='../../data/goodbooks-10k-master/'\n",
    "OUTPUT_DIR = '../box-code/data/book_data/big/small/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  book_id  rating\n",
      "0        1      258       5\n",
      "1        2     4081       4\n",
      "2        2      260       5\n",
      "3        2     9296       5\n",
      "4        2     2318       3\n"
     ]
    }
   ],
   "source": [
    "#read in bk_id and usr rating\n",
    "ratings_file = INPUT_DIR + 'ratings.csv'\n",
    "df = pd.read_csv(ratings_file, delimiter=',')\n",
    "df.dataframeName = 'ratings.csv'\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tag_id tag_name\n",
      "0       0        -\n",
      "1       1     --1-\n",
      "2       2    --10-\n",
      "3       3    --12-\n",
      "4       4   --122-\n"
     ]
    }
   ],
   "source": [
    "#read in all tag name and tag_id\n",
    "tag_name_file = INPUT_DIR + 'tags.csv'\n",
    "df_tag_name = pd.read_csv(tag_name_file, delimiter=',')\n",
    "df_tag_name.dataframeName = 'tags.csv'\n",
    "#print(df_tag_name.size)\n",
    "print(df_tag_name.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   goodreads_book_id  tag_id   count\n",
      "0                  1   30574  167697\n",
      "1                  1   11305   37174\n",
      "2                  1   11557   34173\n",
      "3                  1    8717   12986\n",
      "4                  1   33114   12716\n"
     ]
    }
   ],
   "source": [
    "#read in goodreads_book_id and their labeled tags with tag_id\n",
    "bk_tag_file = INPUT_DIR + 'book_tags.csv'\n",
    "df_bk_tag = pd.read_csv(bk_tag_file, delimiter=',')\n",
    "df_bk_tag.dataframeName = 'book_tags.csv'\n",
    "#df_bk_tag.drop(columns=['count']) drop count\n",
    "print(df_bk_tag.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1232\n"
     ]
    }
   ],
   "source": [
    "#read in valid tag names\n",
    "genre_name_file = INPUT_DIR + \"book-genres.txt\"\n",
    "df_valid_tag = pd.read_csv(genre_name_file, sep= \"\\n\")\n",
    "df_valid_tag.dataframeName = 'book-genres.txt'\n",
    "df_valid_tag = df_valid_tag[~df_valid_tag.genres.str.contains(\" \")]#delete the lines that counts how many books has the tag\n",
    "print(df_valid_tag.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of tags obtained from website: 1232\n",
    "#number of tags in the tag id vs name datafile:  34252\n",
    "#overlap of the two: 833"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in bk id and goodreads book id, later convert all goodreads bk id to bk id\n",
    "bk_id_file = INPUT_DIR + 'books.csv'\n",
    "df_bk_id = pd.read_csv(bk_id_file, delimiter=',')\n",
    "df_bk_id.dataframeName = 'books.csv'\n",
    "#print(df_bk_id.head(10))\n",
    "df_bk_id=df_bk_id[['book_id','goodreads_book_id', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#drop unwanted data in the metadata \n",
    "print(len(df_bk_id))\n",
    "df_bk_id = df_bk_id[df_bk_id['title'].isin(small_title_set)]\n",
    "print(len(df_bk_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dict map goodreads bk id to bk id, we will use bk id to train\n",
    "id_name_dict={} #key: good_read_id, val: bk_id\n",
    "small_book_id_set = set()\n",
    "small_gd_read_id_set = set()\n",
    "title_bk_id_dict = {} #key bk_id val: bk title\n",
    "for index, row in df_bk_id.iterrows():\n",
    "    id_name_dict[row['goodreads_book_id']] = row['book_id'] \n",
    "    small_book_id_set.add(row['book_id'] )\n",
    "    small_gd_read_id_set.add(row['goodreads_book_id'])\n",
    "    title_bk_id_dict[row['book_id']] = row['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2, 3, 4, 8354, 6, 7047, 8, 4234}\n",
      "{2657, 3, 11870085, 32453, 41865, 252938, 5107, 93724}\n"
     ]
    }
   ],
   "source": [
    "print(small_book_id_set)\n",
    "print(small_gd_read_id_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Harry Potter and the Philosopher's Stone\n",
      "3 Twilight\n",
      "4 To Kill a Mockingbird\n",
      "6 The Fault in Our Stars\n",
      "8 The Catcher in the Rye\n",
      "4234 Twilight\n",
      "7047 Twilight\n",
      "8354 Twilight\n"
     ]
    }
   ],
   "source": [
    "for k, v in title_bk_id_dict.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1232\n"
     ]
    }
   ],
   "source": [
    "valid_gen = set([])#set of names of valid tags, this list is obtained from the goodreads website\n",
    "for index, row in df_valid_tag.iterrows():\n",
    "    valid_gen.add(row['genres'])\n",
    "print(len(valid_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833\n"
     ]
    }
   ],
   "source": [
    "#create dictionary of valid tag id and tag names, key: valid tag id, value: valid tag name\n",
    "valid_tag_dict = {}\n",
    "for index, row in df_tag_name.iterrows():\n",
    "    tag_name = row['tag_name']\n",
    "    tag_id = row['tag_id']\n",
    "    if tag_name in valid_gen:\n",
    "        valid_tag_dict[tag_id] = tag_name \n",
    "print(len(valid_tag_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5976479\n",
      "84331\n"
     ]
    }
   ],
   "source": [
    "#drop unwanted data in the rating data\n",
    "print(len(df))\n",
    "df = df[df['book_id'].isin(small_book_id_set)]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999912\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "#drop unwanted data in the rating data\n",
    "print(len(df_bk_tag))\n",
    "df_bk_tag = df_bk_tag[df_bk_tag['goodreads_book_id'].isin(small_gd_read_id_set)]\n",
    "print(len(df_bk_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "#preprocess usr rating data, prepare for bk bk pairs\n",
    "df = df[df.rating >= rating_threshold]#Drop all entry with rating lower than the threshold\n",
    "bk_usr_dict = defaultdict(list)#dict with key: bk_id, val: the list of user_ids rated the bk above the rating threshold\n",
    "for index, row in df.iterrows():    \n",
    "    movieId = int(row['book_id'])\n",
    "    usrId = int(row['user_id'])\n",
    "    bk_usr_dict[movieId].append(usrId)\n",
    "\n",
    "for key in list(bk_usr_dict.keys()):#Drop all movie entry if number of rates below the user count threshold \n",
    "    if len(bk_usr_dict[key]) < user_count_threshold:\n",
    "        del bk_usr_dict[key]\n",
    "print(len(bk_usr_dict.keys()))#736 for 4.5 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169\n"
     ]
    }
   ],
   "source": [
    "#create dict of each book and the tags they are labeled with, key: bk_id, val: list of tag names\n",
    "bk_tag_dict = defaultdict(list)\n",
    "valid_data_count = 0## count the number of pieces of valid bk-tag relations \n",
    "for index, row in df_bk_tag.iterrows():\n",
    "    gd_read_id = row['goodreads_book_id']\n",
    "    tag = row['tag_id']\n",
    "    bk_id =id_name_dict[gd_read_id]\n",
    "    #check if the tag is a valid tag, and the bk is valid after thresholding and filtering\n",
    "    if (tag in valid_tag_dict) and (bk_id in bk_usr_dict):\n",
    "        bk_tag_dict[bk_id].append(valid_tag_dict[tag])\n",
    "        valid_data_count += 1##\n",
    "        \n",
    "#there are totally 99912 rows in the bk-tag datafile, valid_data_count is the number of rows we use    \n",
    "print(valid_data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(bk_tag_dict.keys()))\n",
    "print(len(bk_usr_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginal_prob(movie_id, count_matrix, num_users):\n",
    "    '''function to get the marginal prob:\n",
    "       P(movie_id1)       \n",
    "    '''\n",
    "    margn_count = count_matrix[ movie_id]\n",
    "    return margn_count/num_users\n",
    "\n",
    "def joint_prob(movie_id1, movie_id2, count_matrix, num_users):\n",
    "    '''function to get the joint prob:\n",
    "        P(movie_id1, movie_id2)\n",
    "    '''\n",
    "    key = (movie_id1, movie_id2) if movie_id1<= movie_id2 else (movie_id2, movie_id1) \n",
    "    joint_count = count_matrix[key] \n",
    "    return joint_count/num_users\n",
    "\n",
    "def conditional_prob(movie_id1, movie_id2, count_matrix, marginal_matrix):\n",
    "    '''function to get the conditional prob:\n",
    "        P(movie_id1 | movie_id2)       \n",
    "    '''\n",
    "    key = (movie_id1, movie_id2) if movie_id1<= movie_id2 else (movie_id2, movie_id1)\n",
    "    joint_count = count_matrix[key]\n",
    "    if joint_count == 0:\n",
    "        return 0\n",
    "    margn_count = marginal_matrix[movie_id2]\n",
    "    '''\n",
    "   \n",
    "        print(\"------\")\n",
    "        print(\"id1: \", movie_id1, \"id2: \", movie_id2)\n",
    "        print(count_matrix[(movie_id1, movie_id2)])\n",
    "        print(marginal_matrix[movie_id1], marginal_matrix[movie_id2])\n",
    "        print(joint_count,margn_count,  joint_count/margn_count)\n",
    "        print(\"------\")\n",
    "   '''\n",
    "    return joint_count/margn_count\n",
    "\n",
    "#given ordered pair of key(a,b), generate both p(b|a) and p(a|b)\n",
    "def data_generation(a,b, count_matrix, marginal_matrix):\n",
    "    p_a_b = conditional_prob(a, b, count_matrix, marginal_matrix)#p(a|b)\n",
    "    p_b_a = conditional_prob(b, a, count_matrix, marginal_matrix)#p(b|a)\n",
    "    return(((a,b),p_b_a), ((b,a),p_a_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the movie_genre_master file\n",
    "file = open(OUTPUT_DIR+\"book_genre_master.txt\", \"w\") \n",
    "for movie_id in list(bk_tag_dict.keys()):\n",
    "    for genre_id in bk_tag_dict[movie_id]:\n",
    "        file.write(\"IsA\\t\"+str(movie_id)+\"\\t\" + str(genre_id) + \"\\t\" + str(1)+\"\\n\")\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usr_bk_dict: dict with key: user, val: the book_id this usr rated above given threshold\n",
    "usr_bk_dict = defaultdict(list)\n",
    "for key, val in bk_usr_dict.items():\n",
    "    for i in val:\n",
    "        usr_bk_dict[i].append(key)\n",
    "        \n",
    "#to make sure if a user rate a movie, the user only rate the movie once\n",
    "for key, val in usr_bk_dict.items():\n",
    "    usr_bk_dict[key] = list(set(val))\n",
    "\n",
    "#movie_movie_count: key: (bk_id_i, bk_id_j) (bk_id_i != bk_id_j and bk_id_i < bk_id_j) \n",
    "#                 val: co-ocurrence count of bk_id_i and bk_id_j\n",
    "#movie_movie_count_marginal: key: (bk_id_i) val: ocurrence count of bk_id_i in the dataset\n",
    "movie_movie_count =  defaultdict(lambda: 0)\n",
    "movie_movie_count_marginal = defaultdict(lambda:0)\n",
    "for key, val in usr_bk_dict.items():\n",
    "    for i in range(len(val)):\n",
    "        movie_movie_count_marginal[val[i]] += 1 #marginal count\n",
    "        for j in range(i+1, len(val)):#marginal count not included in book_book_count\n",
    "            movie_movie_count[(val[i], val[j]) if val[i] <= val[j] else (val[j], val[i])] += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_gen_count =  defaultdict(lambda: 0)\n",
    "gen_gen_count_marginal = defaultdict(lambda:0)\n",
    "\n",
    "for key, val in bk_tag_dict.items():\n",
    "     for i in range(len(val)):\n",
    "        gen_gen_count_marginal[val[i]] += 1 #marginal count\n",
    "        for j in range(i+1, len(val)):#marginal count not included in book_book_count\n",
    "            gen_gen_count[(val[i], val[j]) if val[i] <= val[j] else (val[j], val[i])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the movie vocab file\n",
    "file = open(OUTPUT_DIR+\"book_vocabulary.txt\", \"w\") \n",
    "marginal_keys = list(movie_movie_count_marginal.keys())\n",
    "for i in marginal_keys:\n",
    "    file.write(str(i)+\"\\n\") \n",
    "file.close() \n",
    "\n",
    "#create the movie marginal prob file, order of value match order of books id in vocab file\n",
    "file = open(OUTPUT_DIR+\"book_marginal_prob.txt\", \"w\") \n",
    "N = len(usr_bk_dict)#number of user\n",
    "for i in marginal_keys:\n",
    "    file.write(str(marginal_prob(i, movie_movie_count_marginal, N))+\"\\n\")\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the genre vocab file\n",
    "file = open(OUTPUT_DIR+\"genre_vocabulary.txt\", \"w\") \n",
    "marginal_keys = list(gen_gen_count_marginal.keys())\n",
    "for i in marginal_keys:\n",
    "    file.write(str(i)+\"\\n\") \n",
    "file.close() \n",
    "\n",
    "#create the genre marginal prob file, order of value match order of books id in vocab file\n",
    "file = open(OUTPUT_DIR+\"genre_marginal_prob.txt\", \"w\") \n",
    "N = len(bk_tag_dict)#number of total movies\n",
    "for i in marginal_keys:\n",
    "    file.write(str(marginal_prob(i, gen_gen_count_marginal, N))+\"\\n\")\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(movie_movie_count.items())\n",
    "movie_movie_master_data=[]\n",
    "for data in temp:\n",
    "    a,b = data_generation(data[0][0],data[0][1], movie_movie_count, movie_movie_count_marginal)\n",
    "    movie_movie_master_data.append(a)\n",
    "    movie_movie_master_data.append(b)\n",
    "#create the train data file\n",
    "file = open(OUTPUT_DIR + \"book_book_master.txt\", \"w\") \n",
    "for i in movie_movie_master_data:\n",
    "    if str(i[1])!=\"0\":\n",
    "        file.write(\"IsA\\t\"+str(i[0][0])+\"\\t\" + str(i[0][1]) + \"\\t\" + str(i[1])+\"\\n\")\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(gen_gen_count.items())\n",
    "gen_gen_master_data=[]\n",
    "for data in temp:\n",
    "    a,b = data_generation(data[0][0],data[0][1], gen_gen_count, gen_gen_count_marginal)\n",
    "    gen_gen_master_data.append(a)\n",
    "    gen_gen_master_data.append(b)\n",
    "#create the train data file\n",
    "file = open(OUTPUT_DIR + \"genre_genre_master.txt\", \"w\") \n",
    "for i in gen_gen_master_data:\n",
    "    if str(i[1])!=\"0\":\n",
    "        file.write(\"IsA\\t\"+str(i[0][0])+\"\\t\" + str(i[0][1]) + \"\\t\" + str(i[1])+\"\\n\")\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
