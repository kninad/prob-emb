{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../../data/goodbooks-10k-master/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_file = datadir + 'ratings.csv'\n",
    "df = pd.read_csv(ratings_file, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dataframeName = 'ratings.csv'\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (max(df['book_id']), min(df['book_id']))\n",
    "print (max(df['user_id']), min(df['user_id']))#len of the set of user_id is 53424 here\n",
    "print (max(df['rating']), min(df['rating']))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First create a threshold for the ratings to consider: rating_threshold\n",
    "#Drop all entry with rating lower than the threshold\n",
    "rating_threshold = 3.5\n",
    "df = df[df.rating >= rating_threshold]\n",
    "print(len(df))\n",
    "user_id_set = set(df['user_id'])\n",
    "movie_id_set = set(df['book_id'])\n",
    "print(len(user_id_set))\n",
    "print(len(movie_id_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict with key: book_id, val: the list of user_ids rated the book above the rating threshold\n",
    "book_dict = defaultdict(list)\n",
    "for index, row in df.iterrows():    \n",
    "    bookId = int(row['book_id'])\n",
    "    usrId = int(row['user_id'])\n",
    "    book_dict[bookId].append(usrId)\n",
    "print(len(book_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usercount threshold, only keep the bk_id if the bk is rated by user for more than user_count_threshold times\n",
    "user_count_threshold = 100\n",
    "for key in list(book_dict.keys()):\n",
    "    if len(book_dict[key]) < user_count_threshold:\n",
    "        #book_dict[key] = [0]\n",
    "        del book_dict[key]\n",
    "print(len(book_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict with key: user, val: the bookID this usr rated above given threshold\n",
    "#in the current implementation, rating a bk 3.5 has the same effect as rating a bk 5, as long as the score is above threshold, it does not matter\n",
    "user_dict = defaultdict(list)\n",
    "for key, val in book_dict.items():\n",
    "    for i in val:\n",
    "        user_dict[i].append(key)\n",
    "print(len(user_dict))#53304 if user_count_threshold = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Question, can we use the rating below for ex, 2.5 as an negative association?\n",
    "# Answer: negative association is no association. We can use low ratings to calculate how strong people would dislike the pair together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make sure if a user rate a book, the user only rate the book once\n",
    "for key, val in user_dict.items():\n",
    "    user_dict[key] = list(set(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#marginal counts included, without marginal counts, the dict len is 20537173\n",
    "# withou maginal count added the book_book_count dict len is 20547173\n",
    "\n",
    "#book_book_count key: (bk_id_i, bk_id_j) (bk_id_i != bk_id_j and bk_id_i < bk_id_j) val: co-ocurrence count of bk_id_i and bk_id_j\n",
    "#book_book_count_marginal key: (bk_id_i) val: ocurrence count of bk_id_i in the dataset\n",
    "book_book_count =  defaultdict(lambda: 0)\n",
    "book_book_count_marginal = defaultdict(lambda:0)\n",
    "for key, val in user_dict.items():\n",
    "    for i in range(len(val)):\n",
    "        book_book_count_marginal[val[i]] += 1#marginal count\n",
    "        for j in range(i+1, len(val)):#marginal count not included\n",
    "           # if val[i] == val[j]: #error check\n",
    "            #    print(\"val[i] == val[j], error\")\n",
    "            book_book_count[(val[i], val[j]) if val[i] <= val[j] else (val[j], val[i])] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(book_book_count))\n",
    "print(len(book_book_count_marginal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(book_book_count[(10,11)])\n",
    "print(book_book_count[(10.0,11.0)])\n",
    "print(book_book_count[(10,10)])# when marginal count was included in the book_book_count dict, this val was 10562\n",
    "print(book_book_count_marginal[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginal_prob(movie_id, count_matrix, num_users):\n",
    "    '''function to get the marginal prob:\n",
    "        P(movie_id1)       \n",
    "    '''\n",
    "    margn_count = count_matrix[ movie_id]\n",
    "    return margn_count/num_users\n",
    "\n",
    "\n",
    "def joint_prob(movie_id1, movie_id2, count_matrix, num_users):\n",
    "    '''function to get the joint prob:\n",
    "        P(movie_id1, movie_id2)\n",
    "    '''\n",
    "    key = (movie_id1, movie_id2) if movie_id1<= movie_id2 else (movie_id2, movie_id1) \n",
    "    joint_count = count_matrix[key] \n",
    "    return joint_count/num_users\n",
    "\n",
    "\n",
    "def conditional_prob(movie_id1, movie_id2, count_matrix, marginal_matrix):\n",
    "    '''function to get the conditional prob:\n",
    "        P(movie_id1 | movie_id2)       \n",
    "    '''\n",
    "    key = (movie_id1, movie_id2) if movie_id1<= movie_id2 else (movie_id2, movie_id1)\n",
    "    joint_count = count_matrix[key]\n",
    "    if joint_count == 0:\n",
    "        return 0\n",
    "    margn_count = marginal_matrix[movie_id2]\n",
    "    return joint_count/margn_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"../box-code/data/book_data/\"\n",
    "#create the vocab file\n",
    "file = open(BASE_DIR+\"vocabulary.txt\", \"w\") \n",
    "marginal_keys = list(book_book_count_marginal.keys())\n",
    "for i in marginal_keys:\n",
    "    file.write(str(i)+\"\\n\") \n",
    "file.close() \n",
    "\n",
    "#create the marginal prob file, order of value match order of books id in vocab file\n",
    "file = open(BASE_DIR+\"book_marginal_prob.txt\", \"w\") \n",
    "N = len(user_dict)#number of user\n",
    "for i in marginal_keys:\n",
    "    #file.write(str(book_book_count_marginal[i]/N)+\"\\n\")\n",
    "    file.write(str(marginal_prob(i, book_book_count_marginal, N))+\"\\n\")\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "maxval = max([v for k,v in book_book_count.items()])\n",
    "print(maxval)#11992\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given ordered pair of key(a,b), generate both p(b|a) and p(a|b)\n",
    "def data_generation(a,b, count_matrix, marginal_matrix):\n",
    "    p_a_b = conditional_prob(a, b, count_matrix, marginal_matrix)#p(a|b)\n",
    "    p_b_a = conditional_prob(b, a, count_matrix, marginal_matrix)#p(b|a)\n",
    "    return(((a,b),p_b_a), ((b,a),p_a_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, dev, test split\n",
    "split = [0.8, 0.1, 0.1]\n",
    "#shuffle the data\n",
    "items = list(book_book_count.items())\n",
    "items = random.sample(items, len(items))\n",
    "#make the split\n",
    "n = len(items)\n",
    "#print(n)\n",
    "train_split = int(split[0]*n)\n",
    "dev_split = int(train_split+ split[1]*n)\n",
    "train_data_half = items[:train_split]\n",
    "dev_data_half = items[train_split : dev_split]\n",
    "test_data_half= items[dev_split :]\n",
    "#print(len(train_data), len(dev_data), len(test_data))\n",
    "\n",
    "#augment the train dev and test dataset\n",
    "train_data=[]\n",
    "dev_data=[]\n",
    "test_data=[]\n",
    "\n",
    "for data in train_data_half:\n",
    "    a,b = data_generation(data[0][0],data[0][1], book_book_count, book_book_count_marginal)\n",
    "    train_data.append(a)\n",
    "    train_data.append(b)\n",
    "    \n",
    "for data in dev_data_half:\n",
    "    a,b = data_generation(data[0][0],data[0][1], book_book_count, book_book_count_marginal)\n",
    "    dev_data.append(a)\n",
    "    dev_data.append(b)\n",
    "    \n",
    "for data in test_data_half:\n",
    "    a,b = data_generation(data[0][0],data[0][1], book_book_count, book_book_count_marginal)\n",
    "    test_data.append(a)\n",
    "    test_data.append(b)\n",
    "    \n",
    "#reshuffle the train, dev and test dataset\n",
    "train_data = random.sample(train_data, len(train_data))\n",
    "dev_data = random.sample(dev_data, len(dev_data))\n",
    "test_data = random.sample(test_data, len(test_data))\n",
    "#print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the train data file\n",
    "file = open(BASE_DIR + \"book_train.txt\", \"w\") \n",
    "for i in train_data:\n",
    "    if str(i[1])!=\"0\":\n",
    "        file.write(\"IsA\\t\"+str(i[0][0])+\"\\t\" + str(i[0][1]) + \"\\t\" + str(i[1])+\"\\n\")\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dev data file\n",
    "file = open(BASE_DIR + \"book_dev.txt\", \"w\") \n",
    "for i in dev_data:\n",
    "    if str(i[1])!=\"0\":\n",
    "        file.write(\"IsA\\t\"+str(i[0][0])+\"\\t\" + str(i[0][1]) + \"\\t\" + str(i[1])+\"\\n\")\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the test data file\n",
    "file = open(BASE_DIR + \"book_test.txt\", \"w\") \n",
    "for i in test_data:\n",
    "    if str(i[1])!=\"0\":\n",
    "        file.write(\"IsA\\t\"+str(i[0][0])+\"\\t\" + str(i[0][1]) + \"\\t\" + str(i[1])+\"\\n\")\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the test data file\n",
    "file = open(BASE_DIR + \"book_train_test.txt\", \"w\") \n",
    "for i in train_data:\n",
    "    if str(i[1])!=\"0\":\n",
    "        file.write(\"IsA\\t\"+str(i[0][0])+\"\\t\" + str(i[0][1]) + \"\\t\" + str(i[1])+\"\\n\")\n",
    "for i in dev_data:\n",
    "    if str(i[1])!=\"0\":\n",
    "        file.write(\"IsA\\t\"+str(i[0][0])+\"\\t\" + str(i[0][1]) + \"\\t\" + str(i[1])+\"\\n\")\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = len(user_id_set)\n",
    "print(num_users)\n",
    "print(min(user_id_set), max(user_id_set))\n",
    "print(\"marginal\")\n",
    "print(marginal_prob(10, book_book_count, num_users))\n",
    "print(marginal_prob(11, book_book_count, num_users))\n",
    "print(\"joint\")\n",
    "print(joint_prob(10, 11, book_book_count, num_users))\n",
    "print(joint_prob(11, 10, book_book_count, num_users))\n",
    "print(\"conditional\")\n",
    "#print(conditional_prob(10, 11, book_book_count))\n",
    "#print(conditional_prob(11, 10, book_book_count))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have the book_book_pair and the methods to calculate any pair's joint/ conditional\n",
    "#prob, if we need, we can generate the entire joint/conditional prob matrix as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Sample example\n",
    "# Conditioning CAN be less than the marginal! \n",
    "# ref: 2018-box-paper table-1\n",
    "\n",
    "for k in final_dict.keys():\n",
    "    p1 = conditional_prob(10, k, count_matrix)\n",
    "    p2 = marginal_prob(10, count_matrix, N)\n",
    "    if p1 <= p2:\n",
    "        print(k, p1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo\n",
    "#Filter out tags that does not make sense\n",
    "#Right now I only delete the entry in the book_tags.csv if the count is less than a threshold\n",
    "#We can also manuallly remove tags in the tags.csv if we think the tag does not make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a dict betweer goodread_book_id and the book_id used in this dataset\n",
    "books = datadir + 'books.csv'\n",
    "df_books = pd.read_csv(books, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.dataframeName = 'books.csv'\n",
    "df_books= df_books[['book_id', 'goodreads_book_id']]\n",
    "print(df_books.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict with key: goodreads_book_id, val: book_id \n",
    "book_id_dict = defaultdict(lambda:-1)\n",
    "for index, row in df_books.iterrows():    \n",
    "    bookId = int(row['book_id'])\n",
    "    GoodReadId = int(row['goodreads_book_id'])\n",
    "    book_id_dict[GoodReadId]=bookId\n",
    "print(len(book_id_dict))\n",
    "print(book_id_dict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load book_tags file\n",
    "book_tags = datadir + 'book_tags.csv'\n",
    "df_book_tags = pd.read_csv(book_tags, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_book_tags.dataframeName = 'book_tags.csv'\n",
    "print(df_book_tags.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_book_tags.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (max(df_book_tags['goodreads_book_id']), min(df_book_tags['goodreads_book_id']))\n",
    "print (max(df_book_tags['tag_id']), min(df_book_tags['tag_id']))\n",
    "print (max(df_book_tags['count']), min(df_book_tags['count']))\n",
    "print(len(df_book_tags))\n",
    "#There are negative counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove entry if tag count is lower than given threshold, in which case the association between the tag and the book is\n",
    "#not strong\n",
    "tag_count_threshold = 500\n",
    "df_book_tags = df_book_tags[df_book_tags['count'] >= tag_count_threshold]\n",
    "print(len(df_book_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the good_read_book_id to book_id in this dataframe\n",
    "for index, row in df_book_tags.iterrows():\n",
    "    bookId = book_id_dict[int(row['goodreads_book_id'])]\n",
    "    df_book_tags.set_value(index,'goodreads_book_id', bookId) \n",
    "print(df_book_tags.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the column name from goodread_id to book_id\n",
    "df_book_tags.rename(columns={'goodreads_book_id': 'book_id'}, inplace=True)\n",
    "print(df_book_tags.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict with key: book_id, val: tag_id, to list all the tags every book has\n",
    "book_tag_dict = defaultdict(list)\n",
    "for index, row in df_book_tags.iterrows():    \n",
    "    bookId = int(row['book_id'])\n",
    "    tagId = int(row['tag_id'])\n",
    "    book_tag_dict[bookId].append(tagId)\n",
    "print(len(book_tag_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#marginal counts included\n",
    "#here the tag tag pair is incremented by one if a book is listed with both of the two tags\n",
    "tag_tag_count =  defaultdict(lambda: 0)\n",
    "for key, val in book_tag_dict.items():\n",
    "    for i in range(len(val)):\n",
    "        for j in range(i, len(val)):\n",
    "            tag_tag_count[(val[i], val[j]) if val[i] <= val[j] else (val[j], val[i])] += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tag_tag_count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
