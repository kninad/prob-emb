{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "rootdir = \"/home/ninad/Desktop/Link-to-sem4/dsis/prob-emb/fb-poincare/data/book_data/\"\n",
    "\n",
    "# Remember to change this\n",
    "# data_dir = rootdir + \"exp1.1_pretrn_ext/\"  # pre-train folder\n",
    "data_dir = rootdir + \"exp2.3_baseline_notaxo/\"  # No-pretrain folder\n",
    "prob_val = 0.01    # probability threshold\n",
    "\n",
    "# Set this to None if no-pretrain data folders\n",
    "files_genre = None\n",
    "# files_genre = [\"genre_genre_master.txt\", \"genre_genre_eval.txt\"]\n",
    "\n",
    "files_book = [\"book_dev.txt\", \"book_train.txt\", \"book_test.txt\", \"book_train_eval.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_list(data_filepath, prob_threshold):\n",
    "    \"\"\"Function to create a list of training tuples. It is according\n",
    "    to the training data format specified for the poincare model. Also\n",
    "    writes a csv file to disk.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_filepath : str\n",
    "        csv file Path having the conditional probabilities. format is\n",
    "        like - IsA \\t term1 \\t term2 \\t prob.    \n",
    "    prob_threshold : float\n",
    "        threshold for the conditional probability. Only pairs having \n",
    "        prob greater than this will be considered.\n",
    "    outFile : str\n",
    "        File name to which output the modified training file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data_list : list\n",
    "        List of training tuples (pairs) having 2 terms which satisfy \n",
    "        the threshold requirement.             \n",
    "    \"\"\"\n",
    "    # data_list = []    \n",
    "    df = pd.read_csv(data_filepath, header=None, delimiter='\\t', usecols=[1,2,3])\n",
    "    df.columns = ['t1', 't2', 'cond_prob']\n",
    "    df = df[df.cond_prob >= prob_threshold]\n",
    "    # drop the 3rd column now., since no use\n",
    "    df.drop('cond_prob', axis=1, inplace=True)\n",
    "    data_list = list(df.itertuples(index=False, name=None))\n",
    "\n",
    "    index = data_filepath.find('.txt')\n",
    "    outFile = data_filepath[:index] + \"_hb_gensim.csv\"\n",
    "    with open(outFile, \"w\") as out:\n",
    "        out.write(\"id1,id2,weight\\n\")\n",
    "        for row in data_list:\n",
    "            out.write(\"%s,%s,1\\n\" % (row[0], row[1]))\n",
    "    return data_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_mod_data(data_filepath, prob_threshold):\n",
    "    \"\"\"Function to write csv training file for the fb-poincare model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_filepath : str\n",
    "        csv file Path having the conditional probabilities. format is\n",
    "        like - IsA \\t term1 \\t term2 \\t prob.    \n",
    "    prob_threshold : float\n",
    "        threshold for the conditional probability. Only pairs having \n",
    "        prob greater than this will be considered.         \n",
    "    \"\"\"\n",
    "    # data_list = []    \n",
    "    df = pd.read_csv(data_filepath, header=None, delimiter='\\t', usecols=[1,2,3])\n",
    "    df.columns = ['id1', 'id2', 'weight']\n",
    "    df = df[df.weight >= prob_threshold]\n",
    "    index = data_filepath.find('.txt')\n",
    "    outFile = data_filepath[:index] + \"_hb.csv\"\n",
    "    df.to_csv(outFile, sep=',', index=False)    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_files(datadir, file_list, genre_list=None, prob_t=0.01):\n",
    "    \"\"\"Function to create new training files for hyperbolic models.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datadir: str\n",
    "        Path of the data directory where all the training files are located\n",
    "    file_list: list (of str)\n",
    "        List of filenames in data dir which need to be transformed\n",
    "    genre_list: list (of str)\n",
    "        List of genre specific files to be modified. Defaults is None (if there\n",
    "        are no such genre specific files in the datadir)\n",
    "    prob_t: float\n",
    "        probability threshold to be considered for dropping out edges.\n",
    "        Default value: 0.01\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for f in file_list:\n",
    "        fpath = datadir + f\n",
    "        write_mod_data(fpath, prob_t)\n",
    "    \n",
    "    if genre_list:\n",
    "        for gf in genre_list:\n",
    "            gpath = datadir + gf\n",
    "            write_mod_data(gpath, prob_t)\n",
    "    \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_files(datadir=data_dir, file_list=files_book, genre_list=files_genre, prob_t=prob_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
